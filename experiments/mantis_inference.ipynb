{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lorenz/Repos/extractify/backend\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "WORKING_DIR = os.path.dirname(os.path.abspath('./'))\n",
    "print(WORKING_DIR)\n",
    "sys.path.append(WORKING_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../dataset/mantis_json_dataset_with_intents/mantis_utterance_category.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Mistral\n",
      "current_model: AIModelType.MISTRAL_MIXTRAL_8x22B\n",
      "Generate sync\n",
      "promp \n",
      "Gegeben ist folgende Anfrage:s\n",
      "\n",
      "Query:\n",
      "What is the difference when speaking about 'LOB' and 'binary' data? Is it the same, in terms of binary data being stored in a separate filegroup, or are there differences?\n",
      "\n",
      "Extrahiere die gewünschten Filterwerte aus der Konversation, nutze dabei nur die zur Verfügung stehenden Filterwerte. Bedenke aber auch implizite Filterwerte, die nicht explizit genannt werden,\n",
      "aber aus dem Kontext hervorgehen und helfen dem Kunden das passende Produkt zu finden.\n",
      "\n",
      "Denke dabei Schritt für Schritt vor und nutze die Funktionen, die dir zur Verfügung stehen. Erfinde keine neuen Werte in den Filter Werten.\n",
      "Wenn du für das Gespräch keine passendes Filter Werte findest, gib ein leeres Array zurück.\n",
      "\n",
      "response: {'category': 'dba'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from entity_linking import EntityLinking\n",
    "from foundation_models.chat_openai import AIModelType\n",
    "from schema import topic_schema\n",
    "current_model = AIModelType.MISTRAL_MIXTRAL_8x22B\n",
    "\n",
    "\n",
    "async def link_entities(message: str):\n",
    "    # generate function call schema\n",
    "    schema = topic_schema\n",
    "    \n",
    "    # gemerate function calling schema\n",
    "    llm_module = EntityLinking(schema=schema,model=current_model)\n",
    "    \n",
    "    print(\"current_model:\", current_model)\n",
    "    \n",
    "    if current_model == AIModelType.MISTRAL_LARGE or current_model == AIModelType.MISTRAL_MIXTRAL_8x22B or current_model == AIModelType.MISTRAL_SMALL:\n",
    "        filter_generator_output = llm_module.generate_sync(conversation=message)\n",
    "        return filter_generator_output\n",
    "    if current_model == AIModelType.GPT4_O or current_model == AIModelType.GPT4_TURBO or current_model == AIModelType.GPT4_O_MINI or current_model == AIModelType.GPT3 or current_model == AIModelType.GOOGLE_GEMINI_PRO or current_model == AIModelType.CLAUDE_OPUS or current_model == AIModelType.CLAUDE_SONNET:\n",
    "        filter_generator_output = await llm_module.generate_response_generic(conversation=message)\n",
    "    else:\n",
    "        filter_generator_output = await llm_module.generate_async(conversation=message)\n",
    "        \n",
    "    print(\"filter_generator_output:\", filter_generator_output)\n",
    "    \n",
    "    return filter_generator_output\n",
    "        \n",
    "    \n",
    "# test the function\n",
    "message = \"What is the difference when speaking about 'LOB' and 'binary' data? Is it the same, in terms of binary data being stored in a separate filegroup, or are there differences?\"\n",
    "response = await link_entities(message)\n",
    "print(\"response:\", response)\n",
    "\n",
    "# save to json file\n",
    "with open('./temp.json', 'w') as f:\n",
    "    json.dump(response, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over rows with iterrows()\n",
    "import asyncio\n",
    "import json\n",
    "\n",
    "tasks = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    predicted_entities = row[4]\n",
    "\n",
    "    if predicted_entities is not None and type(predicted_entities) == str:\n",
    "        print(\"Already predicted entities\")\n",
    "        continue\n",
    "\n",
    "    query = row[1]\n",
    "    actual_category = row[2]\n",
    "    print(actual_category)\n",
    "    print(query)\n",
    "\n",
    "    async def recognize_and_return_index(\n",
    "        index, message: str\n",
    "    ):\n",
    "        (filter_generator_output, recognized_filters) = (\n",
    "            await link_entities(\n",
    "                message=message,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print(recognized_filters)\n",
    "\n",
    "        df.at[index, \"Prediction\"] = json.dumps(recognized_filters)\n",
    "        return index\n",
    "\n",
    "    print(index)\n",
    "    \n",
    "    try:\n",
    "        await recognize_and_return_index(\n",
    "        index=index,\n",
    "        message=query,\n",
    "    )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    # wait to avoid rate limiting\n",
    "    await asyncio.sleep(5)\n",
    "\n",
    " \n",
    "    # write to csv\n",
    "    df.to_json(f\"prediction_{current_model}_v1.json\", index=False, orient=\"records\")\n",
    "\n",
    "\n",
    "print(len(tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    if type(s) == int:\n",
    "        return str(s)\n",
    "    \"\"\"Normalize a string by removing spaces, converting to lowercase, and replacing dashes.\"\"\"\n",
    "    return s.replace(' ', '').replace('-', '').replace('/','').lower()\n",
    "\n",
    "mapping = {\n",
    "    \"ultrahd4k\": \"ultrahd\",\n",
    "    \"größerals84zoll\": 'gr\\\\u00f6\\\\u00dferals84zoll',\n",
    "    \"größerals19zoll\": 'gr\\\\u00f6\\\\u00dferals19zoll',\n",
    "    \"144hz\": \"144hz\",\n",
    "}\n",
    "\n",
    "speicherkapazitaet_mapping = {\n",
    "    \"256\" : \"256gb\",\n",
    "    \"512\" : \"512gb\",\n",
    "    \"1024\" : \"1024gb\",\n",
    "    \"128\" : \"128gb\",\n",
    "    \"64\" : \"64gb\",\n",
    "}\n",
    "\n",
    "bildwiederholungsfrequenz_mapping = {\n",
    "    \"60\" : \"60hz\",\n",
    "    \"120\" : \"120hz\",\n",
    "    \"144\" : \"144hz\",\n",
    "    \"165\": \"165hz\",\n",
    "    \"240\" : \"240hz\",\n",
    "}\n",
    "\n",
    "\n",
    "def split_entities_in_separated_entities(filter) -> list[tuple]:\n",
    "    separated_entities = []\n",
    "    for (key,values) in filter.items():\n",
    "        for value in values:\n",
    "            normalized_value = normalize_string(value)\n",
    "            mapped_value = mapping.get(normalized_value, normalized_value)\n",
    "            if key == \"speicherkapazitaet\":\n",
    "                mapped_value = speicherkapazitaet_mapping.get(normalized_value, normalized_value)\n",
    "            if key == \"bildwiederholungsfrequenz\":\n",
    "                mapped_value = bildwiederholungsfrequenz_mapping.get(normalized_value, normalized_value)\n",
    "            if key == \"preis\":\n",
    "                mapped_value = value\n",
    "                print(\"preis\", value)\n",
    "            separated_entities.append((key, mapped_value))\n",
    "            \n",
    "    return separated_entities\n",
    "\n",
    "def calculate_tp_fn_fp(actual: list[tuple], predicted: list[tuple]):\n",
    "    \"\"\"\n",
    "    Calculates the true positives (tp), false negatives (fn), and false positives (fp) \n",
    "    for a given set of actual and predicted entities.\n",
    "\n",
    "    Args:\n",
    "        actual (list[tuple]): The list of actual entities.\n",
    "        predicted (list[tuple]): The list of predicted entities.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the counts of tp, fn, fp, and tn.\n",
    "    \"\"\"\n",
    "\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "\n",
    "    fp_entities = []\n",
    "    fn_entities = []\n",
    "\n",
    "    if len(actual) == 0 and len(predicted) == 0:\n",
    "        tn = 1\n",
    "        return tp, fn, fp, tn, fp_entities,fn_entities\n",
    "\n",
    "\n",
    "    for entity in actual:\n",
    "        if entity in predicted:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "            fn_entities.append((actual, entity))\n",
    "\n",
    "    for entity in predicted:\n",
    "        if entity not in actual:\n",
    "            fp += 1\n",
    "            fp_entities.append((actual, entity))\n",
    "\n",
    "    return tp, fn, fp, tn, fp_entities, fn_entities\n",
    "\n",
    "\n",
    "def calculate_precision_recall_f1(tp, fn, fp):\n",
    "    if tp + fp > 0:\n",
    "        precision = tp / (tp + fp)\n",
    "    else:\n",
    "        precision = 0\n",
    "\n",
    "    if tp + fn > 0:\n",
    "        recall = tp / (tp + fn)\n",
    "    else:\n",
    "        recall = 0\n",
    "\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import json\n",
    "df = pd.read_json(f\"prediction_LLAMA_3_70B_v1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "total_tp = 0\n",
    "total_fn = 0\n",
    "total_fp = 0\n",
    "total_tn = 0\n",
    "\n",
    "false_positives = []\n",
    "false_negatives = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    query = row[1]\n",
    "    print(query)\n",
    "    print(row[3])\n",
    "    actual_entities = json.loads(row[3])\n",
    "    actual_category = row[2]\n",
    "\n",
    "    if actual_category == \"Other\":\n",
    "        continue\n",
    "\n",
    "    predicted_entities = row[4]\n",
    "\n",
    "    # check if predicted entities is nan\n",
    "    if isinstance(predicted_entities, float) and math.isnan(predicted_entities):\n",
    "        predicted_entities = []\n",
    "    elif type(predicted_entities) == dict:\n",
    "        continue\n",
    "    elif predicted_entities is None:\n",
    "        predicted_entities = []\n",
    "    else:\n",
    "        predicted_entities = json.loads(predicted_entities)\n",
    "\n",
    "    # convert predicted entities to dict\n",
    "    converted_predicted_entities = {}\n",
    "    \n",
    "    for entity in predicted_entities:\n",
    "        if 'values' in entity:\n",
    "            converted_predicted_entities.update({entity['id'].lower(): entity['values']})\n",
    "        else:\n",
    "            if 'maximum' in entity or 'minimum' in entity:\n",
    "                converted_predicted_entities.update({entity['id'].lower(): [str(entity.get(\"minimum\",0)),str(entity.get(\"maximum\",0))]})\n",
    "\n",
    "\n",
    "    # print(\"converted_predicted_entities\",converted_predicted_entities)\n",
    "    # process predicted entities\n",
    "    predicted_entities = split_entities_in_separated_entities(converted_predicted_entities)\n",
    "    actual_entities = split_entities_in_separated_entities(actual_entities)\n",
    "    \n",
    "    print(\"predicted_entities\",predicted_entities)\n",
    "    print(\"actual_entities\",actual_entities)\n",
    "    \n",
    "    # add category tuple to actual entities\n",
    "    actual_entities.append((\"kategorie\", normalize_string(actual_category)))\n",
    "    \n",
    "    \n",
    "    (tp, fn, fp, tn, fp_entities,fn_entities) = calculate_tp_fn_fp(actual_entities, predicted_entities)\n",
    "    total_tp += tp\n",
    "    total_fn += fn\n",
    "    total_fp += fp\n",
    "    total_tn += tn\n",
    "\n",
    "    if len(fp_entities) > 0:\n",
    "        false_positives.append((query, fp_entities))\n",
    "\n",
    "    if len(fn_entities) > 0:\n",
    "        false_negatives.append((query, fn_entities))\n",
    "\n",
    "\n",
    "# calculate precision, recall, and f1\n",
    "precision, recall, f1 = calculate_precision_recall_f1(total_tp, total_fn, total_fp)\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {f1}\")\n",
    "print(\"total tn\", total_tn)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write false positives to file\n",
    "with open('false_positives.txt', 'w') as f:\n",
    "    for fp in false_positives:\n",
    "        f.write(f\"{fp}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write false negatives to file\n",
    "with open('false_negatives.txt', 'w') as f:\n",
    "    for fn in false_negatives:\n",
    "        f.write(f\"{fn}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the results in a confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# create confusion matrix\n",
    "conf_matrix = np.array([[total_tp, total_fn], [total_fp, total_tn]])\n",
    "\n",
    "# create heatmap\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['True', 'False'], yticklabels=['True', 'False'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have lots of false negatives, as the model does not have all filter ids in schema for Function Call Model. We use custom filter ids for the experiment, to give them a fair chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_entities(x):\n",
    "    if isinstance(x, float) and math.isnan(x):\n",
    "        x = []\n",
    "    else:\n",
    "        x = json.loads(x)\n",
    "\n",
    "    return {entity[\"id\"]: entity[\"values\"] for entity in x}\n",
    "\n",
    "\n",
    "# Detect all filters that are never recognized\n",
    "actual_entities = df[\"Entities\"].apply(json.loads).explode().dropna().unique()\n",
    "\n",
    "predicted_entities = df[\"Recognized_Filters_Prediction\"].apply(process_entities)\n",
    "predicted_entities = predicted_entities.explode().dropna().unique()\n",
    "\n",
    "never_recognized = [entity for entity in actual_entities if entity not in predicted_entities]\n",
    "print(never_recognized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(\"Category\")\n",
    "unique_entities = grouped['Entities'].apply(lambda x: x.apply(json.loads).explode().dropna().unique())\n",
    "    \n",
    "# store to json\n",
    "unique_entities.to_json('filters_per_category.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shopping-assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
